{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "669d3514",
   "metadata": {},
   "source": [
    "\n",
    "### Handling Time Series Data in Pandas\n",
    "\n",
    "Time series data is data that is recorded over time â€” like daily stock prices, monthly sales numbers, or hourly weather readings.\n",
    "\n",
    "Pandas is very powerful for working with time series because it has special tools to:\n",
    "\n",
    "* **Work with dates and times easily:**\n",
    "  You can convert strings or numbers into datetime objects so pandas knows they represent dates or times.\n",
    "\n",
    "* **Index data by time:**\n",
    "  You can set a datetime column as the index, which makes it simple to select data from a specific day, month, or year.\n",
    "\n",
    "* **Resample data:**\n",
    "  If you have data recorded every minute but want to see daily or monthly summaries, pandas lets you easily group and aggregate the data by different time intervals.\n",
    "\n",
    "* **Handle missing dates:**\n",
    "  Pandas can fill in missing dates in your series, so your data is continuous, which is helpful for analysis.\n",
    "\n",
    "* **Shift and lag data:**\n",
    "  You can move data forward or backward in time to compare values at different time points, useful for calculating changes or growth.\n",
    "\n",
    "* **Rolling and expanding windows:**\n",
    "  Pandas lets you calculate moving averages or cumulative sums over a sliding window of time to spot trends or smooth out noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7729f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series with DatetimeIndex:\n",
      "2014-07-04    0\n",
      "2014-08-04    1\n",
      "2015-07-04    2\n",
      "2015-08-04    3\n",
      "dtype: int64\n",
      "\n",
      "Data between '2014-07-04' and '2015-07-04':\n",
      "2014-07-04    0\n",
      "2014-08-04    1\n",
      "2015-07-04    2\n",
      "dtype: int64\n",
      "\n",
      "Data for the year 2015:\n",
      "2015-07-04    2\n",
      "2015-08-04    3\n",
      "dtype: int64\n",
      "\n",
      "DatetimeIndex created by pd.to_datetime():\n",
      "DatetimeIndex(['2015-07-03', '2015-07-04', '2015-07-06', '2015-07-07',\n",
      "               '2015-07-08'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "Converted to PeriodIndex with daily frequency:\n",
      "PeriodIndex(['2015-07-03', '2015-07-04', '2015-07-06', '2015-07-07',\n",
      "             '2015-07-08'],\n",
      "            dtype='period[D]')\n",
      "\n",
      "TimedeltaIndex showing difference from first date:\n",
      "TimedeltaIndex(['0 days', '1 days', '3 days', '4 days', '5 days'], dtype='timedelta64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Create a DatetimeIndex from a list of date strings\n",
    "index = pd.DatetimeIndex(['2014-07-04', '2014-08-04', '2015-07-04', '2015-08-04'])\n",
    "\n",
    "# 2. Create a Series with data indexed by these dates\n",
    "data = pd.Series([0, 1, 2, 3], index=index)\n",
    "\n",
    "# Print the series\n",
    "print(\"Original Series with DatetimeIndex:\")\n",
    "print(data)\n",
    "# The series values are linked to specific dates, which act as index labels\n",
    "\n",
    "# 3. Use date-based slicing to select data between two dates\n",
    "print(\"\\nData between '2014-07-04' and '2015-07-04':\")\n",
    "print(data['2014-07-04':'2015-07-04'])\n",
    "# This returns all rows from start date up to and including the end date\n",
    "\n",
    "# 4. Select all data for a given year by passing just the year string\n",
    "print(\"\\nData for the year 2015:\")\n",
    "print(data['2015'])\n",
    "# Pandas automatically filters all dates in 2015\n",
    "\n",
    "# 5. Creating datetime objects in different formats using pd.to_datetime()\n",
    "dates = pd.to_datetime([\n",
    "    datetime(2015, 7, 3),          # datetime object\n",
    "    '4th of July, 2015',           # string with natural language format\n",
    "    '2015-Jul-6',                  # string with year-month-day format\n",
    "    '07-07-2015',                  # string with month-day-year format\n",
    "    '20150708'                     # compact string with no separators\n",
    "])\n",
    "\n",
    "print(\"\\nDatetimeIndex created by pd.to_datetime():\")\n",
    "print(dates)\n",
    "# Converts various date representations to a uniform DatetimeIndex\n",
    "\n",
    "# 6. Convert the DatetimeIndex to a PeriodIndex with daily frequency\n",
    "periods = dates.to_period('D')\n",
    "print(\"\\nConverted to PeriodIndex with daily frequency:\")\n",
    "print(periods)\n",
    "# PeriodIndex stores time intervals rather than single timestamps\n",
    "\n",
    "# 7. Calculate time differences (TimedeltaIndex) by subtracting the first date from all dates\n",
    "time_deltas = dates - dates[0]\n",
    "print(\"\\nTimedeltaIndex showing difference from first date:\")\n",
    "print(time_deltas)\n",
    "# This shows the elapsed time (in days) between each date and the first date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4e5fbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Daily Data:\n",
      "2023-01-01    0\n",
      "2023-01-02    1\n",
      "2023-01-03    2\n",
      "2023-01-04    3\n",
      "2023-01-05    4\n",
      "2023-01-06    5\n",
      "2023-01-07    6\n",
      "2023-01-08    7\n",
      "2023-01-09    8\n",
      "2023-01-10    9\n",
      "Freq: D, dtype: int64\n",
      "\n",
      "\n",
      "resampled data \n",
      " 2023-01-01     3\n",
      "2023-01-04    12\n",
      "2023-01-07    21\n",
      "2023-01-10     9\n",
      "Freq: 3D, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Resampling and Frequency Conversion\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a time series with daily data starting from Jan 1, 2023, 10 days total\n",
    "dates = pd.date_range('2023-01-01', periods=10, freq='D')\n",
    "data1 = pd.Series(np.arange(10), index=dates)\n",
    "\n",
    "print(\"\\nOriginal Daily Data:\")\n",
    "print(data1)\n",
    "\n",
    "# Resample the daily data to 3-day periods and sum the values in each 3-day block\n",
    "resampled = data1.resample('3D').sum()\n",
    "\n",
    "print(\"\\n\\nresampled data \\n\",resampled)\n",
    "\n",
    "# Use Case:\n",
    "# Resampling is useful when you want to aggregate time series data at different time intervals,\n",
    "# e.g., converting daily stock prices to weekly or monthly sums, averages, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9c9f382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing data utc\n",
      " 2023-01-01 00:00:00+00:00    0\n",
      "2023-01-02 00:00:00+00:00    1\n",
      "2023-01-03 00:00:00+00:00    2\n",
      "2023-01-04 00:00:00+00:00    3\n",
      "2023-01-05 00:00:00+00:00    4\n",
      "2023-01-06 00:00:00+00:00    5\n",
      "2023-01-07 00:00:00+00:00    6\n",
      "2023-01-08 00:00:00+00:00    7\n",
      "2023-01-09 00:00:00+00:00    8\n",
      "2023-01-10 00:00:00+00:00    9\n",
      "Freq: D, dtype: int64\n",
      "printing data est\n",
      " 2022-12-31 19:00:00-05:00    0\n",
      "2023-01-01 19:00:00-05:00    1\n",
      "2023-01-02 19:00:00-05:00    2\n",
      "2023-01-03 19:00:00-05:00    3\n",
      "2023-01-04 19:00:00-05:00    4\n",
      "2023-01-05 19:00:00-05:00    5\n",
      "2023-01-06 19:00:00-05:00    6\n",
      "2023-01-07 19:00:00-05:00    7\n",
      "2023-01-08 19:00:00-05:00    8\n",
      "2023-01-09 19:00:00-05:00    9\n",
      "Freq: D, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Time zone Handling\n",
    "# Localize the naive datetime index to UTC (assign timezone info)\n",
    "data_utc = data1.tz_localize('UTC')\n",
    "print(\"printing data utc\\n\",data_utc)\n",
    "\n",
    "# Convert the time series from UTC to US Eastern Time\n",
    "data_est = data_utc.tz_convert('US/Eastern')\n",
    "print(\"printing data est\\n\",data_est)\n",
    "\n",
    "# Use Case:\n",
    "# Timezone localization is important when working with data from multiple regions,\n",
    "# ensuring all timestamps refer to the correct local time for accurate analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling mean\n",
      " 2023-01-01    NaN\n",
      "2023-01-02    NaN\n",
      "2023-01-03    1.0\n",
      "2023-01-04    2.0\n",
      "2023-01-05    3.0\n",
      "2023-01-06    4.0\n",
      "2023-01-07    5.0\n",
      "2023-01-08    6.0\n",
      "2023-01-09    7.0\n",
      "2023-01-10    8.0\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#rolling  window and moving statistics\n",
    "# Calculate a rolling mean with a window of 3 days\n",
    "rolling_mean = data1.rolling(window=3).mean()\n",
    "print(\"rolling mean\\n\",rolling_mean)\n",
    "#first two values will be NaN since there are not enough data points to calculate the mean\n",
    "\n",
    "# Use Case:\n",
    "\n",
    "# Rolling functions help smooth noisy data, calculate moving averages in finance,\n",
    "# or detect trends by aggregating data over a sliding window of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ee33e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01    NaN\n",
      "2023-01-02    NaN\n",
      "2023-01-03    0.0\n",
      "2023-01-04    1.0\n",
      "2023-01-05    2.0\n",
      "2023-01-06    3.0\n",
      "2023-01-07    4.0\n",
      "2023-01-08    5.0\n",
      "2023-01-09    6.0\n",
      "2023-01-10    7.0\n",
      "Freq: D, dtype: float64\n",
      "2023-01-01    2.0\n",
      "2023-01-02    3.0\n",
      "2023-01-03    4.0\n",
      "2023-01-04    5.0\n",
      "2023-01-05    6.0\n",
      "2023-01-06    7.0\n",
      "2023-01-07    8.0\n",
      "2023-01-08    9.0\n",
      "2023-01-09    NaN\n",
      "2023-01-10    NaN\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Shift the time series forward by 2 periods (days), adding NaNs at the start\n",
    "shifted_forward = data1.shift(2)\n",
    "\n",
    "# Shift the time series backward by 2 periods (days), adding NaNs at the end\n",
    "shifted_backward = data1.shift(-2)\n",
    "\n",
    "print(shifted_forward)\n",
    "print(shifted_backward)\n",
    "\n",
    "# Use Case:\n",
    "# Shifting is useful to compare current data points with previous/future points,\n",
    "# e.g., calculating day-over-day changes or creating lagged variables for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b852df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01    0.0\n",
      "2023-01-02    1.0\n",
      "2023-01-03    2.0\n",
      "2023-01-04    2.0\n",
      "2023-01-05    2.0\n",
      "2023-01-06    5.0\n",
      "2023-01-07    6.0\n",
      "2023-01-08    7.0\n",
      "2023-01-09    8.0\n",
      "2023-01-10    9.0\n",
      "Freq: D, dtype: float64\n",
      "2023-01-01    0.0\n",
      "2023-01-02    1.0\n",
      "2023-01-03    2.0\n",
      "2023-01-04    5.0\n",
      "2023-01-05    5.0\n",
      "2023-01-06    5.0\n",
      "2023-01-07    6.0\n",
      "2023-01-08    7.0\n",
      "2023-01-09    8.0\n",
      "2023-01-10    9.0\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Copy the series and introduce missing values (NaN) at index 3 and 4\n",
    "data_with_nan = data1.copy()\n",
    "data_with_nan.iloc[3:5] = np.nan\n",
    "\n",
    "# Forward fill missing data with last valid observation\n",
    "ffill = data_with_nan.ffill()\n",
    "\n",
    "# Backward fill missing data with next valid observation\n",
    "bfill = data_with_nan.bfill()\n",
    "\n",
    "print(ffill)\n",
    "print(bfill)\n",
    "\n",
    "# Use Case:\n",
    "# Time series often have gaps; filling missing values ensures continuity for analysis,\n",
    "# like filling sensor readings or financial data where missing days occur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c3ad1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-01-01 00:00:00', '2023-01-01 01:00:00',\n",
      "               '2023-01-01 02:00:00', '2023-01-01 03:00:00',\n",
      "               '2023-01-01 04:00:00', '2023-01-01 05:00:00',\n",
      "               '2023-01-01 06:00:00', '2023-01-01 07:00:00',\n",
      "               '2023-01-01 08:00:00', '2023-01-01 09:00:00',\n",
      "               '2023-01-01 10:00:00', '2023-01-01 11:00:00',\n",
      "               '2023-01-01 12:00:00', '2023-01-01 13:00:00',\n",
      "               '2023-01-01 14:00:00', '2023-01-01 15:00:00',\n",
      "               '2023-01-01 16:00:00', '2023-01-01 17:00:00',\n",
      "               '2023-01-01 18:00:00', '2023-01-01 19:00:00',\n",
      "               '2023-01-01 20:00:00', '2023-01-01 21:00:00',\n",
      "               '2023-01-01 22:00:00', '2023-01-01 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq='h')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KARAN\\AppData\\Local\\Temp\\ipykernel_28080\\4241124197.py:2: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hourly_dates = pd.date_range('2023-01-01', periods=24, freq='H')\n"
     ]
    }
   ],
   "source": [
    "# Generate a sequence of hourly timestamps for one day starting Jan 1, 2023\n",
    "hourly_dates = pd.date_range('2023-01-01', periods=24, freq='H')\n",
    "print(hourly_dates)\n",
    "\n",
    "# Use Case:\n",
    "# Useful for creating a complete timeline or index for data collection at regular intervals,\n",
    "# e.g., hourly weather observations or system logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af61ed5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2023-01', '2023-02', '2023-03', '2023-04'], dtype='period[M]')\n",
      "PeriodIndex(['2023-02', '2023-03', '2023-04', '2023-05'], dtype='period[M]')\n"
     ]
    }
   ],
   "source": [
    "# Create a range of monthly periods starting Jan 2023 (4 months)\n",
    "periods = pd.period_range('2023-01', periods=4, freq='M')\n",
    "print(periods)\n",
    "\n",
    "# Add one month to each period to shift them forward\n",
    "periods_plus_one = periods + 1\n",
    "print(periods_plus_one)\n",
    "\n",
    "# Use Case:\n",
    "# Period objects represent time intervals rather than points.\n",
    "# Ideal for monthly, quarterly, or yearly reporting periods, and performing interval arithmetic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df885a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               value\n",
      "date                \n",
      "2023-01-01  0.567489\n",
      "2023-01-02  0.457893\n",
      "2023-01-03  0.521085\n",
      "2023-01-04  0.145141\n",
      "2023-01-05  0.640011\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with dates and random values\n",
    "df = pd.DataFrame({\n",
    "    'date': pd.date_range('2023-01-01', periods=5),\n",
    "    'value': np.random.rand(5)\n",
    "})\n",
    "\n",
    "# Set 'date' column as index to allow time-based indexing and slicing\n",
    "df.set_index('date', inplace=True)\n",
    "print(df)\n",
    "\n",
    "# Use Case:\n",
    "# Setting the datetime column as index optimizes filtering and slicing by dates,\n",
    "# essential for time series analysis or resampling operations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "394718df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  year  month  day\n",
      "0 2023-01-01  2023      1    1\n",
      "1 2023-01-02  2023      1    2\n",
      "2 2023-01-03  2023      1    3\n"
     ]
    }
   ],
   "source": [
    "dates = pd.date_range('2023-01-01', periods=3, freq='D')\n",
    "df = pd.DataFrame({'date': dates})\n",
    "\n",
    "# Extract year, month, and day components from 'date' column using dt accessor\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Use Case:\n",
    "# Accessors let you break down timestamps into meaningful components for grouping,\n",
    "# filtering, or feature engineering (e.g., seasonal effects in models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2e013b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01    NaN\n",
      "2023-01-02    6.0\n",
      "2023-01-03    8.0\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Two series with overlapping but not identical dates\n",
    "s1 = pd.Series([1, 2, 3], index=pd.date_range('2023-01-01', periods=3))\n",
    "s2 = pd.Series([4, 5], index=pd.date_range('2023-01-02', periods=2))\n",
    "\n",
    "# Adding aligns data by dates and results in NaN where no overlap exists\n",
    "result = s1 + s2\n",
    "print(result)\n",
    "\n",
    "# Use Case:\n",
    "# When combining multiple time series, pandas aligns them on the datetime index,\n",
    "# which is essential for correct arithmetic, merges, or joins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca226a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01    10\n",
      "2023-01-03    20\n",
      "2023-01-10    30\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create time series with irregular date intervals (not daily)\n",
    "irregular_dates = pd.to_datetime(['2023-01-01', '2023-01-03', '2023-01-10'])\n",
    "irregular_series = pd.Series([10, 20, 30], index=irregular_dates)\n",
    "\n",
    "print(irregular_series)\n",
    "\n",
    "# Use Case:\n",
    "# Many real-world time series are irregular (e.g., transaction logs or event data),\n",
    "# and pandas handles these smoothly without requiring regular intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65097e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date      1000 non-null   datetime64[ns]\n",
      " 1   category  1000 non-null   category      \n",
      "dtypes: category(1), datetime64[ns](1)\n",
      "memory usage: 9.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with 1000 rows, each representing a date starting from 2023-01-01\n",
    "df = pd.DataFrame({\n",
    "    'date': pd.date_range('2023-01-01', periods=1000),  # generates 1000 consecutive dates\n",
    "    # Create a 'category' column with repeated values: pattern ['A', 'B', 'C', 'A', 'B'] repeated 200 times\n",
    "    'category': ['A', 'B', 'C', 'A', 'B'] * 200  \n",
    "})\n",
    "\n",
    "# Convert 'category' column to categorical dtype\n",
    "# This converts the column from object (string) type to 'category' type,\n",
    "# which is more memory efficient because pandas stores the unique categories once,\n",
    "# and then uses integer codes internally for the repeated values.\n",
    "df['category'] = df['category'].astype('category')\n",
    "\n",
    "# Display DataFrame info to see memory usage and data types\n",
    "print(df.info())\n",
    "\n",
    "# Use Case:\n",
    "# Categorical dtype is very useful when you have a column with repeated string values.\n",
    "# It reduces memory usage significantly compared to storing the raw strings repeatedly.\n",
    "# It also speeds up operations like grouping, filtering, and sorting because\n",
    "# pandas works internally with the integer codes instead of strings.\n",
    "# This optimization is common in large datasets with categorical data such as gender, product type, or status codes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
